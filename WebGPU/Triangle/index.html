<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Document</title>
    <style>
      :root {
        color-scheme: light dark;
      }
      #fail {
        position: fixed;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        display: flex;
        justify-content: center;
        align-items: center;
        background: red;
        color: white;
        font-weight: bold;
        font-family: monospace;
        font-size: 16pt;
        text-align: center;
      }
      .blink {
        animation: blinker 2s step-start infinite;
      }
      @keyframes blinker {
        50% {
          opacity: 0;
        }
      }
    </style>
  </head>
  <body>
    <canvas></canvas>
    <script>
      async function main() {
        const adapter = await navigator.gpu?.requestAdapter();
        const device = await adapter?.requestDevice();
        if (!device) {
          fail("need a browser that supports WebGPU");
          return;
        }

        // Get a WebGPU context from the canvas and configure it
        const canvas = document.querySelector("canvas");
        const context = canvas.getContext("webgpu");
        const presentationFormat = navigator.gpu.getPreferredCanvasFormat();
        context.configure({
          device,
          format: presentationFormat,
        });

        const module = device.createShaderModule({
          label: "our hardcoded red triangle shaders",
          code: `
      @vertex fn vs(
        @builtin(vertex_index) vertexIndex : u32
      ) -> @builtin(position) vec4f {
        var pos = array<vec2f, 3>(
          vec2f( 0.0,  0.5),  // top center
          vec2f(-0.5, -0.5),  // bottom left
          vec2f( 0.5, -0.5)   // bottom right
        );

        return vec4f(pos[vertexIndex], 0.0, 1.0);
      }

      @fragment fn fs() -> @location(0) vec4f {
        return vec4f(1, 0, 0, 1);
      }
    `,
        });

        const pipeline = device.createRenderPipeline({
          label: "our hardcoded red triangle pipeline",
          layout: "auto",
          vertex: {
            module,
            entryPoint: "vs",
          },
          fragment: {
            module,
            entryPoint: "fs",
            targets: [{ format: presentationFormat }],
          },
        });

        const renderPassDescriptor = {
          label: "our basic canvas renderPass",
          colorAttachments: [
            {
              // view: <- to be filled out when we render
              clearValue: [0.3, 0.3, 0.3, 1],
              loadOp: "clear",
              storeOp: "store",
            },
          ],
        };

        function render() {
          // Get the current texture from the canvas context and
          // set it as the texture to render to.
          renderPassDescriptor.colorAttachments[0].view = context
            .getCurrentTexture()
            .createView();

          // make a command encoder to start encoding commands
          const encoder = device.createCommandEncoder({ label: "our encoder" });

          // make a render pass encoder to encode render specific commands
          const pass = encoder.beginRenderPass(renderPassDescriptor);
          pass.setPipeline(pipeline);
          pass.draw(3); // call our vertex shader 3 times.
          pass.end();

          const commandBuffer = encoder.finish();
          device.queue.submit([commandBuffer]);
        }

        render();
      }

      function fail(msg) {
        // eslint-disable-next-line no-alert
        alert(msg);
      }

      main();
    </script>
  </body>
</html>
